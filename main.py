import streamlit as st
from openai import OpenAI
from PIL import Image
from dotenv import load_dotenv
import os
import io
from Agent import MedicationAgent
from gtts import gTTS
from audio_recorder_streamlit import audio_recorder

# í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)
agent = MedicationAgent()

st.title("ğŸ’Š ê³ ì–‘ì´ ì´ˆë°¥")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì„¸ì…˜ì´ ìƒˆë¡œ ì‹œì‘ëœ ê²½ìš°)
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "image_uploaded" not in st.session_state:
    st.session_state.image_uploaded = False

if "question_count" not in st.session_state:
    st.session_state.question_count = 0

if "new_question" not in st.session_state:
    st.session_state.new_question = False

# ì¸í„°ë„· ì°½ ìƒˆë¡œê³ ì¹¨ ë˜ëŠ” ì ‘ì† ì‹œ ì´ˆê¸°í™”: ì„¸ì…˜ ìƒíƒœ ì²´í¬
if len(st.session_state.chat_history) == 0 and st.session_state.question_count == 0:
    st.session_state.chat_history = []  # ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    st.session_state.question_count = 0  # ì§ˆë¬¸ ìˆ˜ ì´ˆê¸°í™”
    st.session_state.new_question = False  # ìƒˆ ì§ˆë¬¸ í”Œë˜ê·¸ ì´ˆê¸°í™”
    st.session_state.image_uploaded = False  # ì´ë¯¸ì§€ ì—…ë¡œë“œ ìƒíƒœ ì´ˆê¸°í™”
    st.info("ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤!")

# ì´ë¯¸ì§€ ì—…ë¡œë“œ ë¶€ë¶„
if not st.session_state.image_uploaded:
    image_file = st.file_uploader("ì•½ ì´ë¯¸ì§€ ì—…ë¡œë“œ ", type=["jpg", "jpeg", "png"])
    if image_file:
        image = Image.open(image_file)
        image.save("image.png")
        st.image(image, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€", use_container_width=True)
        st.success("ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.session_state.image_uploaded = True
        st.session_state.new_question = True
else:
    st.image("image.png", caption="í˜„ì¬ ì´ë¯¸ì§€", use_container_width=True)

# ì§ˆë¬¸ ë£¨í”„ íŠ¸ë¦¬ê±°
if st.button("â• ìƒˆ ì§ˆë¬¸ ì¶”ê°€í•˜ê¸°"):
    st.session_state.new_question = True

# ì•„ì´ì—ê²Œ ì•½ì„ ë¨¹ì—¬ë„ ë˜ëŠ”ì§€ ë¬¼ì–´ë³´ëŠ” ìƒí™©ì„ ì²˜ë¦¬
if st.session_state.new_question:
    st.markdown(f"### ğŸ¤ ì§ˆë¬¸ {st.session_state.question_count + 1} ë…¹ìŒ")

    # ìŒì„± ë…¹ìŒ ì»´í¬ë„ŒíŠ¸
    audio_bytes = audio_recorder(
        energy_threshold=(-1.0, 1.0),
        pause_threshold=10.0,
        sample_rate=16000,
        key=f"recorder_{st.session_state.question_count}"
    )

    if audio_bytes:
        # ë…¹ìŒ ì˜¤ë””ì˜¤ ì¬ìƒ
        st.audio(audio_bytes, format="audio/wav")
        st.info("Whisper STT ìˆ˜í–‰ ì¤‘...")

        # BytesIOë¡œ ë³€í™˜
        audio_file = io.BytesIO(audio_bytes)
        audio_file.name = f"question_{st.session_state.question_count}.wav"

        # ê¸°ì¡´ STT ì²˜ë¦¬ ë¡œì§
        with st.spinner("ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
            raw_text = transcript.text
            st.markdown(f"ğŸ“ ì¸ì‹ëœ ì§ˆë¬¸: `{raw_text}`")

        # ì§ˆë¬¸ì„ ëª…í™•íˆ ì •ë¦¬
        with st.spinner("GPTê°€ ì§ˆë¬¸ì„ ëª…í™•í•˜ê²Œ ì •ë¦¬ ì¤‘..."):
            clarify_prompt = f"""
            ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ë§ë¡œ ëœ ì§ˆë¬¸ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìëŠ” ì•„ì´ì—ê²Œ ì•½ì„ ì‚¬ìš©í•´ë„ ê´œì°®ì€ì§€ì— ê´€í•œ ë‚´ìš©ì„ ì§ˆë¬¸í•˜ê±°ë‚˜ ì•„ì´ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤.
            ì´ë¥¼ ë” ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
            "{raw_text}"
            """
            gpt_response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ëª¨í˜¸í•œ ì§ˆë¬¸ì„ ëª…í™•íˆ ì •ë¦¬í•˜ëŠ” ì¡°ìˆ˜ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": clarify_prompt}
                ]
            )
            clarified_text = gpt_response.choices[0].message.content.strip()

        st.markdown(f"ğŸ” ëª…í™•í•œ ì§ˆë¬¸: `{clarified_text}`")
        st.session_state.chat_history.append({"question": clarified_text})

        # ì „ì²´ ì§ˆë¬¸ íˆìŠ¤í† ë¦¬ ìƒì„±í•˜ì—¬ Agentì— ì œê³µ (ê³¼ê±° ì§ˆë¬¸ì„ì„ ëª…ì‹œ)
        full_prompt = ""
        for i, item in enumerate(st.session_state.chat_history):
            if i < st.session_state.question_count:  # ê³¼ê±° ì§ˆë¬¸ë§Œ 'ê³¼ê±° ì§ˆë¬¸'ìœ¼ë¡œ ë ˆì´ë¸”ë§
                full_prompt += f"ê³¼ê±° ì…ë ¥ {i+1}: {item['question']}\n í˜„ì¬ ì…ë ¥ {i+1}: {item['answer']}\n"
            else:
                full_prompt += f"í˜„ì¬ ì…ë ¥: {item['question']}\n"

        with st.spinner("ğŸ’Š Agentê°€ ì‘ë‹µ ì¤‘..."):
            answer = agent("ê³¼ê±°ì˜ ì…ë ¥ì€ ì°¸ê³ ë§Œ í•˜ë˜, í˜„ì¬ì˜ ì…ë ¥ì— ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."+full_prompt, image_path="image.png")
            st.session_state.chat_history[-1]["answer"] = answer

        st.text_area("ğŸ¤– Agent ì‘ë‹µ", answer, height=200)

        # TTS ìƒì„±
        with st.spinner("ğŸ”Š TTS ìƒì„± ì¤‘..."):
            tts = gTTS(text=answer, lang="ko")
            audio_path = f"response_{st.session_state.question_count}.mp3"
            tts.save(audio_path)
            st.audio(audio_path, format="audio/mp3")

        # ë‹¤ìŒ ì§ˆë¬¸ì„ ë°›ì„ ì¤€ë¹„
        st.session_state.question_count += 1
        st.session_state.new_question = False

# ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬
if st.session_state.chat_history:
    st.markdown("### ğŸ“š ëŒ€í™” íˆìŠ¤í† ë¦¬")
    for i, item in enumerate(st.session_state.chat_history):
        st.markdown(f"**ì§ˆë¬¸ {i+1}:** {item['question']}")
        st.markdown(f"**ì‘ë‹µ {i+1}:** {item['answer']}")
